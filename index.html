<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <h1>ChatGPT для разработчиков</h1>
    <h2>Самый частый вопрос: можно ли подключать свою базу документов и можно ли по ней нормально работать?</h2>

<p>Можно. Для этого нужно две вещи:</p>

<ol>
    <li>OpenAI может работать с вашей базой, например, вики техподдержки, но её надо векторизовать. Получится, что модель только ищет по ней и может отвечать фрагментом исходника, но может его обрабатывать как текст (то есть сравнивать, анализировать и тому подобное).</li>
    <li>Дальше можно использовать подход <a href="https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa" target="_blank">QA Retrieval Chain</a> для работы с векторной базой. Работает это так: задаём вопрос, LLM формируют запрос к векторной базе, мы вынимаем из неё данные, подкладываем их в вопрос как контекст и передаём в LLM, а они формируют ответ.</li>
</ol>

<p>Но давайте начнём сначала. Основное:</p>

<ol>
    <li>Какого размера промпты могут быть, сколько, какие лимиты, как их частично обходить.</li>
    <li>Как подключается база, как закидывать реально большие документы, как эмбеддится вектор, на каких языках это происходит и тому подобное.</li>
    <li>Разные API.</li>
    <li>Агентная модель GPT Engineer и АutoGPT.</li>
    <li>Фреймворк лангчейн (построение цепочек запросов и разбиение макрозапроса на сотни).</li>
</ol>
<img src="./img/img1.png" alt="" width="200px">
<p>Поехали!</p>

<h2>Совсем ликбез. Что такое ChatGPT и как он «думает»?</h2>

<p>Изначально языковую модель создавали для того, чтобы она умела общаться. В итоге всё началось с моделей продолжения текста и закончилось тем, что эта штука научилась писать код, играть в шахматы, заказывать реактивы и уговаривать кожаных проходить капчу там, где есть недостающие ей данные.</p>

<p>Условно предполагалось два пути развития искусственного интеллекта. Первый — полным копированием человеческого мозга. Для этого взяли мозг мелкого млекопитающего, заморозили, послойно тонко нарезали и начали собирать карту связей нейронов, чтобы получить полную копию и запустить копипастом, не разбираясь, как она работает. Это ветка, которая пока не дала значимых результатов, но всегда считалась перспективной.</p>

<p>Второй путь — создать модель, которая оперирует знаниями всего человечества и «угадывает» ответ на вопрос, не понимая, что делает. Именно этот подход и был реализован. Модель не «знает», что такое чувства, мораль или этика, и генерирует ответы на основе статистических зависимостей, выявленных в ходе обучения. Это означает, что иногда она может давать неточные или даже ошибочные ответы.</p>

<h2>Как работает запрос к ChatGPT?</h2>

<p>В общем случае вы задаёте вопрос, а модель ищет наиболее правильное продолжение текста по своим правилам. При этом процесс повторяется итеративно, каждое новое дополнение (каждое новое слово для упрощения) увеличивает ваш запрос. То есть количество токенов, используемых для генерации ответа, растёт во время исполнения с каждым шагом и анализируется целиком. В интерфейсе подкладываются предыдущие сообщения через Chat, как мы могли бы это сделать через API. Модель помнит несколько последних промптов.</p>

<p>Сколько их будет, зависит от длины самих сообщений и размера контекста. А всё, что в контекст не влезает, забывается.</p>

<p>В базовой модели ChatGPT без дополнительных модулей модель плохо разбирается в математике, она оперирует глобальными взаимосвязями, которых достаточно для базовых задач. Чтобы решить этот вопрос, OpenAl сделали через плагины для работы на сайте чата интеграцию с вольфрамом и Code Interprete, с ними математические задачи решаются хорошо.</p>

<p>Кроме того, для разработчиков существуют способы добавить математические библиотеки самостоятельно с использованием системных LLM-промптов или сторонних библиотек, к примеру calculator tool из LangChain-фреймворка.</p>
</body>
</html>